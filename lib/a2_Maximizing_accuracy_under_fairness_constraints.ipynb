{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximizing accuracy under fairness constraints (C-SVM and C-LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import urllib2\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import preprocessing\n",
    "from random import seed, shuffle\n",
    "import a2_loss_funcs as lf \n",
    "import a2_utils as ut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/compas-scores-two-years.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7214, 53)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the features we will use for analysis, the target variable and the sensitive attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_CLASSIFICATION = [\"age_cat\", \"race\", \"sex\", \"priors_count\", \"c_charge_degree\", 'score_text', 'decile_score']\n",
    "CONT_VARIABLES = [\"priors_count\", \"decile_score\"] \n",
    "CLASS_FEATURE = \"two_year_recid\" \n",
    "SENSITIVE_ATTRS = [\"race\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_cat\n",
      "['Greater than 45' '25 - 45' 'Less than 25']\n",
      "--------------------------\n",
      "race\n",
      "['Other' 'African-American' 'Caucasian' 'Hispanic' 'Native American'\n",
      " 'Asian']\n",
      "--------------------------\n",
      "sex\n",
      "['Male' 'Female']\n",
      "--------------------------\n",
      "priors_count\n",
      "[ 0  4  1  2 14  3  7  6  5 13  8  9 21 20 15 10 12 28 19 11 22 23 25 24\n",
      " 36 18 16 33 17 30 27 38 26 37 29 35 31]\n",
      "--------------------------\n",
      "c_charge_degree\n",
      "['F' 'M']\n",
      "--------------------------\n",
      "score_text\n",
      "['Low' 'High' 'Medium']\n",
      "--------------------------\n",
      "decile_score\n",
      "[ 1  3  4  8  6 10  5  9  2  7]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for column in FEATURES_CLASSIFICATION:\n",
    "    print(column)\n",
    "    print(df[column].unique())\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"days_b_screening_arrest\"]) \n",
    "data = df.to_dict('list')\n",
    "for k in data.keys():\n",
    "    data[k] = np.array(data[k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following preprocessing steps are taken based on the [propublica GitHub page](https://github.com/propublica/compas-analysis)\n",
    "\n",
    "\n",
    "- If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
    "- We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "- In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).\n",
    "- We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.logical_and(data[\"days_b_screening_arrest\"]<=30, data[\"days_b_screening_arrest\"]>=-30)\n",
    "\n",
    "idx = np.logical_and(idx, data[\"is_recid\"] != -1)\n",
    "\n",
    "idx = np.logical_and(idx, data[\"c_charge_degree\"] != \"O\") \n",
    "\n",
    "idx = np.logical_and(idx, data[\"score_text\"] != \"NA\")\n",
    "\n",
    "idx = np.logical_and(idx, np.logical_or(data[\"race\"] == \"African-American\", data[\"race\"] == \"Caucasian\"))\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African-American: 3175\n",
      "Caucasian: 2103\n"
     ]
    }
   ],
   "source": [
    "unique_values, value_counts = np.unique(data['race'], return_counts=True)\n",
    "\n",
    "# Display unique values and their counts\n",
    "for value, count in zip(unique_values, value_counts):\n",
    "    print(f\"{value}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people recidivating within two years\n",
      "-1    2795\n",
      " 1    2483\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = data[CLASS_FEATURE]\n",
    "y[y==0] = -1\n",
    "\n",
    "print(\"Number of people recidivating within two years\")\n",
    "print(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([]).reshape(len(y), 0) \n",
    "x_control = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the discrete variables to one-hot encoded columns and scale the continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = []\n",
    "for attr in FEATURES_CLASSIFICATION:\n",
    "    vals = data[attr]\n",
    "    if attr in CONT_VARIABLES:\n",
    "        vals = [float(v) for v in vals]\n",
    "        vals = preprocessing.scale(vals) \n",
    "        vals = np.reshape(vals, (len(y), -1)) \n",
    "\n",
    "    else: \n",
    "        lb = preprocessing.LabelBinarizer()\n",
    "        lb.fit(vals)\n",
    "        vals = lb.transform(vals)\n",
    "\n",
    "    # add to sensitive features dict\n",
    "    if attr in SENSITIVE_ATTRS:\n",
    "        x_control[attr] = vals\n",
    "\n",
    "\n",
    "    # add to learnable features\n",
    "    X = np.hstack((X, vals))\n",
    "\n",
    "    if attr in CONT_VARIABLES: # continuous feature, just append the name\n",
    "        feature_names.append(attr)\n",
    "    else: # categorical features\n",
    "        if vals.shape[1] == 1: # binary features that passed through lib binarizer\n",
    "            feature_names.append(attr)\n",
    "        else:\n",
    "            for k in lb.classes_: # non-binary categorical features, need to add the names for each cat\n",
    "                feature_names.append(attr + \"_\" + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sensitive feature to 1-d array\n",
    "x_control = dict(x_control)\n",
    "for k in x_control.keys():\n",
    "    assert(x_control[k].shape[1] == 1) # make sure that the sensitive feature is binary after one hot encoding\n",
    "    x_control[k] = np.array(x_control[k]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = list(range(0, X.shape[0]))\n",
    "shuffle(perm)\n",
    "X = X[perm]\n",
    "y = y[perm]\n",
    "for k in x_control.keys():\n",
    "    x_control[k] = x_control[k][perm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features we will be using for classification are: ['intercept', 'age_cat_25 - 45', 'age_cat_Greater than 45', 'age_cat_Less than 25', 'race', 'sex', 'priors_count', 'c_charge_degree', 'score_text_High', 'score_text_Low', 'score_text_Medium', 'decile_score'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = ut.add_intercept(X)\n",
    "\n",
    "feature_names = [\"intercept\"] + feature_names\n",
    "assert(len(feature_names) == X.shape[1])\n",
    "print (\"Features we will be using for classification are:\", feature_names, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the p-rule in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 5278\n",
      "# non-protected examples: 2103\n",
      "# protected examples: 3175\n",
      "Non-protected in positive class: 822 (39%)\n",
      "Protected in positive class: 1661 (52%)\n",
      "P-rule is: 134%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "133.84228978676936"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut.compute_p_rule(x_control[\"race\"], y) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_size = 0.7\n",
    "x_train, y_train, x_control_train, x_test, y_test, x_control_test = ut.split_into_train_test(X, y, x_control, train_fold_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logictic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Logistic Regression without applying fairness constraints. For this the the \"apply_fairness_constraints\" value should be set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_fairness_constraints = 0\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "\n",
    "loss_function = lf._logistic_loss\n",
    "sensitive_attrs = [\"race\"]\n",
    "sensitive_attrs_to_cov_thresh = {}\n",
    "gamma = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n",
      "Protected/non-protected in +ve class: 53% / 29%\n",
      "P-rule achieved: 182%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.120\n"
     ]
    }
   ],
   "source": [
    "w = ut.train_model(x_train, y_train, x_control_train, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "p_rule = ut.print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs[0])\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with fairness constraints. For this the the \"apply_fairness_constraints\" value should be set to 1 and the \"sensitive_attrs_to_cov_thresh\" should pass the dict of fairness column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_fairness_constraints = 1\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "\n",
    "loss_function = lf._logistic_loss\n",
    "sensitive_attrs = [\"race\"]\n",
    "sensitive_attrs_to_cov_thresh = {\"race\":0}\n",
    "gamma = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "Protected/non-protected in +ve class: 42% / 42%\n",
      "P-rule achieved: 99%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.025\n"
     ]
    }
   ],
   "source": [
    "w = ut.train_model(x_train, y_train, x_control_train, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "p_rule = ut.print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs[0])\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_fairness_constraints = 0\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "\n",
    "loss_function = lf._hinge_loss\n",
    "sensitive_attrs = [\"race\"]\n",
    "sensitive_attrs_to_cov_thresh = {}\n",
    "gamma = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "Protected/non-protected in +ve class: 57% / 37%\n",
      "P-rule achieved: 155%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.096\n"
     ]
    }
   ],
   "source": [
    "w = ut.train_model(x_train, y_train, x_control_train, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "p_rule = ut.print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs[0])\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_fairness_constraints = 1\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "\n",
    "loss_function = lf._hinge_loss\n",
    "sensitive_attrs = [\"race\"]\n",
    "sensitive_attrs_to_cov_thresh = {\"race\":0}\n",
    "gamma = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "Protected/non-protected in +ve class: 51% / 40%\n",
      "P-rule achieved: 128%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.030\n"
     ]
    }
   ],
   "source": [
    "w = ut.train_model(x_train, y_train, x_control_train, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "p_rule = ut.print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs[0])\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
