{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "63wcxRqora35"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from itertools import combinations, chain\n",
        "import math\n",
        "\n",
        "def powerset(iterable):\n",
        "    \"\"\"Create a powerset of the given iterable.\"\"\"\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
        "\n",
        "def mutual_information(df, features, target):\n",
        "    \"\"\"Calculate mutual information between features and target.\"\"\"\n",
        "    features_list = list(features)\n",
        "    return mutual_info_score(df[target], df[features_list].apply(lambda row: '_'.join(row.values.astype(str)), axis=1))\n",
        "\n",
        "\n",
        "def conditional_mutual_information(df, features, target, conditioned_on):\n",
        "    \"\"\"Calculate conditional mutual information between features and target, conditioned on other features.\"\"\"\n",
        "    features_list = list(features)\n",
        "    conditioned_on_list = list(conditioned_on)\n",
        "\n",
        "    df_combined = df.copy()\n",
        "    df_combined['combined_features'] = df_combined[features_list].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
        "    df_combined['combined_conditioned'] = df_combined[conditioned_on_list].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
        "\n",
        "    grouped = df_combined.groupby('combined_conditioned')\n",
        "    cmi = sum(mutual_info_score(group['combined_features'], group[target]) * len(group) / len(df_combined) for name, group in grouped)\n",
        "\n",
        "    return cmi\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "\n",
        "def calculate_svm_importance(df, features, target):\n",
        "    \"\"\"Estimate feature importance using SVM.\"\"\"\n",
        "    features_list = list(features)\n",
        "\n",
        "    svm = SVC(kernel='linear')\n",
        "    print(df[features_list])\n",
        "    print(df[target])\n",
        "    svm.fit(df[features_list], df[target])\n",
        "\n",
        "\n",
        "    if svm.kernel == 'linear':\n",
        "        importances = svm.coef_[0]\n",
        "        return abs(importances).sum()\n",
        "    else:\n",
        "        raise ValueError(\"SVM kernel is not linear. Feature importance can't be extracted.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def calculate_unique_information(df, features, target):\n",
        "    \"\"\"Estimate unique information provided by a set of features with respect to the target using SVM.\"\"\"\n",
        "    return calculate_svm_importance(df, features, target)\n",
        "\n",
        "def calculate_synergistic_information(df, features, target, complement_features):\n",
        "    \"\"\"Estimate synergistic information provided by a set of features and its complement with respect to the target using SVM.\"\"\"\n",
        "    features_list = list(features)\n",
        "    combined_features = features_list + complement_features\n",
        "    total_info = calculate_svm_importance(df, combined_features, target)\n",
        "    unique_info = calculate_unique_information(df, features_list, target)\n",
        "    synergistic_info = total_info - unique_info\n",
        "    return synergistic_info\n",
        "\n",
        "\n",
        "def calculate_accuracy_coefficient(df, feature_set, target, protected_attribute):\n",
        "    \"\"\"Calculate the accuracy coefficient for a given set of features using SVM.\"\"\"\n",
        "    complement_features = [col for col in df.columns if col not in feature_set and col != target and col != protected_attribute]\n",
        "\n",
        "    unique_info = calculate_unique_information(df, feature_set, target)\n",
        "\n",
        "    synergistic_info = calculate_synergistic_information(df, feature_set, target, complement_features)\n",
        "\n",
        "    accuracy_coefficient = unique_info + synergistic_info\n",
        "    return accuracy_coefficient\n",
        "\n",
        "\n",
        "\n",
        "def calculate_discrimination_coefficient(df, feature_set, target, protected_attribute):\n",
        "    \"\"\"Calculate the discrimination coefficient for a given set of features.\"\"\"\n",
        "    shared_info = mutual_information(df, feature_set, target)\n",
        "    mutual_info_xs_a = mutual_information(df, feature_set, protected_attribute)\n",
        "    conditional_mutual_info_xs_a_y = conditional_mutual_information(df, feature_set, protected_attribute, [target])\n",
        "    return shared_info * mutual_info_xs_a * conditional_mutual_info_xs_a_y\n",
        "\n",
        "\n",
        "def shapley_value(df, features, target, protected_attribute, accuracy_or_discrimination):\n",
        "    \"\"\"Calculate the Shapley value for each feature.\"\"\"\n",
        "    shapley_values = dict.fromkeys(features, 0)\n",
        "    total_features = len(features)\n",
        "\n",
        "    for feature in features:\n",
        "        for feature_set in powerset(set(features) - {feature}):\n",
        "            feature_set_with = set(feature_set).union({feature})\n",
        "            if accuracy_or_discrimination == 'accuracy':\n",
        "                contribution = calculate_accuracy_coefficient(df, feature_set_with, target, protected_attribute) - calculate_accuracy_coefficient(df, feature_set, target, protected_attribute)\n",
        "            else:\n",
        "                contribution = calculate_discrimination_coefficient(df, feature_set_with, target, protected_attribute) - calculate_discrimination_coefficient(df, feature_set, target, protected_attribute)\n",
        "            shapley_values[feature] += (contribution * math.factorial(len(feature_set)) * math.factorial(total_features - len(feature_set) - 1)) / math.factorial(total_features)\n",
        "\n",
        "    return shapley_values\n",
        "\n",
        "\n",
        "def generate_feature_comparison_table(df, features, target, protected_attribute):\n",
        "    \"\"\"Generate a table comparing features with their accuracy and discrimination coefficients.\"\"\"\n",
        "    accuracy_shapley = shapley_value(df, features, target, protected_attribute, 'accuracy')\n",
        "    discrimination_shapley = shapley_value(df, features, target, protected_attribute, 'discrimination')\n",
        "\n",
        "    comparison_table = pd.DataFrame({\n",
        "        'Feature': features,\n",
        "        'Marginal Accuracy Coefficient': [accuracy_shapley[feature] for feature in features],\n",
        "        'Marginal Discrimination Coefficient': [discrimination_shapley[feature] for feature in features]\n",
        "    })\n",
        "\n",
        "    return comparison_table"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "compas_data_final_copy = compas_data_final.copy()\n",
        "\n",
        "features = ['age_cat', 'charge_degree', 'sex', 'priors_counts', 'length_of_stay']\n",
        "for col in columns_to_convert:\n",
        "    compas_data_final_copy[col] = compas_data_final_copy[col].astype(int)\n",
        "\n",
        "feature_list = ['age_cat', 'charge_degree', 'sex', 'priors_counts', 'length_of_stay']\n",
        "sensitive_feature = 'race'\n",
        "feature_comparison_table = generate_feature_comparison_table(compas_data_final_copy, feature_list, 'two_year_recid', sensitive_feature)\n",
        "\n",
        "print(feature_comparison_table)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Pp1JW8yDrdqK",
        "outputId": "ac92b9ce-53ff-45e4-d398-24aaa4552024"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ncompas_data_final_copy = compas_data_final.copy()\\n\\nfeatures = ['age_cat', 'charge_degree', 'sex', 'priors_counts', 'length_of_stay']\\nfor col in columns_to_convert:\\n    compas_data_final_copy[col] = compas_data_final_copy[col].astype(int)\\n\\nfeature_list = ['age_cat', 'charge_degree', 'sex', 'priors_counts', 'length_of_stay']\\nsensitive_feature = 'race'\\nfeature_comparison_table = generate_feature_comparison_table(compas_data_final_copy, feature_list, 'two_year_recid', sensitive_feature)\\n\\nprint(feature_comparison_table)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "51B3LymTrjzs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}